# -*- coding: utf-8 -*-
"""Fraud Detection Using Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UUZkSOZKVPxtHbZHcO1TQPOJpNXG9UK_
"""

import pandas as pd
import numpy as np
import random
random.seed(100)

data=pd.read_csv("train_sample.csv")
data.head()

data.drop(columns=["attributed_time"],inplace=True)
data["click_time"]=pd.to_datetime(data["click_time"])

"""## Let's Perform Some Feature Engineering"""

## Let's Extract some features out of all availabel columns
##########################################################################################################
## Let's see on which hour the click was happend
data["hour"]=data["click_time"].dt.hour.astype("uint8")
#############################################################################################################
## Let's see on which minute the click was happend
data["minute"]=data["click_time"].dt.minute.astype("uint8")
############################################################################################################
## Let's see on which second the click was happend
data["second"]=data["click_time"].dt.second.astype("uint8")
############################################################################################################
## Let's see on which day the click was happend
data["day"]=data["click_time"].dt.day.astype("uint8")
##########################################################################################################
## Let's see on which dayofweek the click was happend
data["day_of_week"]=data["click_time"].dt.dayofweek.astype("uint8")

######################################################################################################
print("Let's divide the day in four section ,See in which section click has happend ")
day_section = 0
for start_time, end_time in zip([0, 6, 12, 18], [6, 12, 18, 24]):
        data.loc[(data['hour'] >= start_time) & (data['hour'] < end_time), 'day_section'] = day_section
        day_section += 1
########################################################################################################
print( "Let's see new clicks count features")
data["n_ip_clicks"]=data[['ip','channel']].groupby(by=["ip"])[["channel"]].transform("count").astype("uint8")
#######################################################################################################
print('Computing the number of clicks associated with a given app per hour...')
data["n_app_clicks"]= data[['app', 'day', 'hour', 'channel']].groupby(by=['app', 'day', 'hour'])[['channel']].transform("count").astype("uint8")
########################################################################################################
print('Computing the number of channels associated with a given IP address within each hour...')
data["n_channels"]=data[['ip','day','hour','channel']].groupby(by=['ip','day','hour'])[['channel']].transform("count").astype("uint8")
########################################################################################################
print('Computing the number of channels associated with ')
data['ip_app_count']=data[['ip','app', 'channel']].groupby(by=['ip', 'app'])[['channel']].transform("count").astype("uint8")
###############################################################################################################
print('Computing the number of channels associated with ')
data["ip_app_os_count"]= data[['ip','app', 'os', 'channel']].groupby(by=['ip', 'app','os'])[['channel']].transform("count").astype("uint8")

data['n_ip_os_day_hh']=data[['ip', 'os', 'day', 'hour', 'channel']].groupby(by=['ip', 'os', 'day','hour'])[['channel']].transform("count").astype("uint8")
#######################################################################################################
data['n_ip_app_day_hh']=data[['ip', 'app', 'day', 'hour', 'channel']].groupby(by=['ip', 'app', 'day','hour'])[['channel']].transform("count").astype("uint8")
#######################################################################################################
data['n_ip_app_os_day_hh']=data[['ip', 'app', 'os', 'day', 'hour', 'channel']].groupby(by=['ip','app', 'os', 'day','hour'])[['channel']].transform("count").astype("uint8")
#########################################################################################################
data['n_ip_app_dev_os']=data[['ip', 'app', 'device', 'os', 'channel']].groupby(by=['ip','app','device','os'])[['channel']].transform("count").astype("uint8")
#########################################################################################################
data['n_ip_dev_os']=data[['ip', 'device', 'os', 'channel']].groupby(by=['ip', 'device', 'os'])[['channel']].transform("count").astype("uint8")
#########################################################################################################

data.is_attributed.value_counts(normalize=True)

data.drop(columns=["click_time"],axis=1,inplace=True)

data["is_attributed"]=data["is_attributed"].astype("uint8")

from sklearn.model_selection import train_test_split
train_X,test_X,train_y,test_y=train_test_split(data.drop("is_attributed",axis=1),data["is_attributed"],stratify=data["is_attributed"],test_size=0.15)

train_X,val_X,train_y,val_y=train_test_split(train_X,train_y,stratify=train_y,test_size=0.1)

import lightgbm as lgb
dtrain = lgb.Dataset(train_X, train_y)
dvalid = lgb.Dataset(val_X, val_y)
dtest = lgb.Dataset(test_X,test_y)

param = {'num_leaves': 64, 'objective': 'binary',"seed":1,'boosting_type': 'dart',  # Use boosting_type="gbrt" for large dataset
    'objective': 'binary',
    'metric': 'auc',
    'learning_rate': 0.1,
    'num_leaves': 11,
    'max_depth': -1, 
    'min_child_samples': 100,
    'max_bin': 100,
    'subsample': 0.9,  # Was 0.7
    'subsample_freq': 1,
    'colsample_bytree': 0.7,
    'min_child_weight': 0,
         'min_split_gain': 0,
    'reg_alpha': 0,
    'reg_lambda': 0}
param['metric'] = 'auc'
num_round = 1000
bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=20)

from sklearn import metrics
ypred = bst.predict(test_X)
score = metrics.roc_auc_score(test_y, ypred)
print(f"Test score: {score}")

"""### Encoding the categorical features:

#### Let's Apply Target Encoding
"""

train_X.columns

cat_features=['ip', 'app', 'device', 'os', 'channel']

import category_encoders as ce


target_enc = ce.TargetEncoder(cols = cat_features)

target_enc.fit(train_X[cat_features], train_y)

train_encoded = train_X.join(target_enc.transform(train_X[cat_features]).add_suffix("_target"))

valid_encoded = val_X.join(target_enc.transform(val_X[cat_features]).add_suffix("_target"))

import lightgbm as lgb
dtrain = lgb.Dataset(train_encoded, train_y)
dvalid = lgb.Dataset(valid_encoded, val_y)
dtest = lgb.Dataset(test_X,test_y)

param = {'num_leaves': 64, 'objective': 'binary',"seed":1,'boosting_type': 'dart',  # Use boosting_type="gbrt" for large dataset
    'objective': 'binary',
    'metric': 'auc',
    'learning_rate': 0.1,
    'num_leaves': 11,
    'max_depth': -1, 
    'min_child_samples': 100,
    'max_bin': 100,
    'subsample': 0.9,  # Was 0.7
    'subsample_freq': 1,
    'colsample_bytree': 0.7,
    'min_child_weight': 0,
         'min_split_gain': 0,
    'reg_alpha': 0,
    'reg_lambda': 0,}
num_round = 1000
bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=20)

test_encoded = test_X.join(target_enc.transform(test_X[cat_features]).add_suffix("_target"))
from sklearn import metrics
ypred = bst.predict(test_encoded)
score = metrics.roc_auc_score(test_y, ypred)
print(f"Test score: {score}")

train_X.columns

pred_y=[1 if a>0.5 else 0 for a in ypred]
from sklearn.metrics import classification_report
print(classification_report(test_y, pred_y))

"""### Let's apply count encoding"""

import category_encoders as ce


target_enc = ce.CountEncoder(cols = cat_features)

target_enc.fit(train_X[cat_features], train_y)

train_encoded = train_X.join(target_enc.transform(train_X[cat_features]).add_suffix("_count"))

valid_encoded = val_X.join(target_enc.transform(val_X[cat_features]).add_suffix("_count"))

import lightgbm as lgb
dtrain = lgb.Dataset(train_encoded, train_y)
dvalid = lgb.Dataset(valid_encoded, val_y)
dtest = lgb.Dataset(test_X,test_y)

param = {'num_leaves': 64, 'objective': 'binary',"seed":1,'boosting_type': 'dart',  # Use boosting_type="gbrt" for large dataset
    'objective': 'binary',
    'metric': 'auc',
    'learning_rate': 0.1,
    'num_leaves': 11,
    'max_depth': -1, 
    'min_child_samples': 100,
    'max_bin': 100,
    'subsample': 0.9,  # Was 0.7
    'subsample_freq': 1,
    'colsample_bytree': 0.7,
    'min_child_weight': 0,
         'min_split_gain': 0,
    'reg_alpha': 0,
    'reg_lambda': 0,}
num_round = 1000
bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=20)

test_encoded = test_X.join(target_enc.transform(test_X[cat_features]).add_suffix("_target"))
from sklearn import metrics
ypred = bst.predict(test_encoded)
score = metrics.roc_auc_score(test_y, ypred)
print(f"Test score: {score}")

"""### Let's Apply catboost Encoding"""

import category_encoders as ce


target_enc = ce.CatBoostEncoder(cols = cat_features,random_state=100)

target_enc.fit(train_X[cat_features], train_y)

train_encoded = train_X.join(target_enc.transform(train_X[cat_features]).add_suffix("_count"))

valid_encoded = val_X.join(target_enc.transform(val_X[cat_features]).add_suffix("_count"))

import lightgbm as lgb
dtrain = lgb.Dataset(train_encoded, train_y)
dvalid = lgb.Dataset(valid_encoded, val_y)
dtest = lgb.Dataset(test_X,test_y)

param = {'num_leaves': 64, 'objective': 'binary',"seed":1,'boosting_type': 'dart',  # I think gbrt would be better, but takes too long to run
    # 'drop_rate': 0.09,  # Rate at which to drop trees
    'objective': 'binary',
    'metric': 'auc',
    'learning_rate': 0.1,
    'num_leaves': 11,
    'max_depth': -1, 
    'min_child_samples': 100,
    'max_bin': 100,
    'subsample': 0.9,  # Was 0.7
    'subsample_freq': 1,
    'colsample_bytree': 0.7,
    'min_child_weight': 0,
         'min_split_gain': 0,
    'reg_alpha': 0,
    'reg_lambda': 0,}
num_round = 1000
bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], early_stopping_rounds=20)

test_encoded = test_X.join(target_enc.transform(test_X[cat_features]).add_suffix("_target"))
from sklearn import metrics
ypred = bst.predict(test_encoded)
score = metrics.roc_auc_score(test_y, ypred)
print(f"Test score: {score}")

"""# <-----------------------------Thank You------------------------------>"""

